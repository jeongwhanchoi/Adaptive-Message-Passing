{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "# taken from https://github.com/gravins/Anti-SymmetricDGN/blob/main/graph_prop_pred/utils/pna_dataset.py\n",
    "\n",
    "TASKS = ['dist', 'ecc', 'lap', 'conn', 'diam', 'rad']\n",
    "NODE_LVL_TASKS = ['dist', 'ecc', 'lap']\n",
    "GRAPH_LVL_TASKS = ['conn', 'diam', 'rad']\n",
    "\n",
    "class GraphPropDataset(InMemoryDataset):\n",
    "    def __init__(self, root, split, task, dim='25-35', pre_transform=None):\n",
    "        assert split in ['train', 'val', 'test']\n",
    "        assert task in TASKS\n",
    "        if not task in ['dist', 'ecc', 'diam']:\n",
    "            raise NotImplementedError('the only tasks implemented are: dist, ecc, diam')\n",
    "\n",
    "        assert dim in ['15-25', '25-35']\n",
    "        self.dim = dim\n",
    "\n",
    "        self.split = split\n",
    "        self.task = task\n",
    "        super().__init__(root)\n",
    "        self.pre_transform = pre_transform\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        print(f'Loaded {self.processed_paths[0]}')\n",
    "\n",
    "    @property\n",
    "    def processed_paths(self):\n",
    "        return [os.path.join(self.root, n) for n in self.processed_file_names]\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [os.path.join(f'{self.split}_{self.task}_{self.dim}_data.pt')]\n",
    "\n",
    "    def process(self):\n",
    "        pass  # reuse the data already split by authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('DATA/Diameter/raw'):\n",
    "    os.makedirs('DATA/Diameter/raw')\n",
    "\n",
    "if not os.path.exists('DATA/Eccentricity/raw'):\n",
    "    os.makedirs('DATA/Eccentricity/raw')\n",
    "\n",
    "if not os.path.exists('DATA/SSSP/raw'):\n",
    "    os.makedirs('DATA/SSSP/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DATA/train_diam_25-35_data.pt\n",
      "Loaded DATA/val_diam_25-35_data.pt\n",
      "Loaded DATA/test_diam_25-35_data.pt\n",
      "Task diam preprocessed\n",
      "Loaded DATA/train_dist_25-35_data.pt\n",
      "Loaded DATA/val_dist_25-35_data.pt\n",
      "Loaded DATA/test_dist_25-35_data.pt\n",
      "Task dist preprocessed\n",
      "Loaded DATA/train_ecc_25-35_data.pt\n",
      "Loaded DATA/val_ecc_25-35_data.pt\n",
      "Loaded DATA/test_ecc_25-35_data.pt\n",
      "Task ecc preprocessed\n"
     ]
    }
   ],
   "source": [
    "for task in ['diam', 'dist', 'ecc']:\n",
    "    data_list = []\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        \n",
    "        dataset = GraphPropDataset('DATA', split, task)\n",
    "        data_list.extend([d for d in dataset])\n",
    "\n",
    "    maps = {'diam': 'Diameter/raw',\n",
    "           'ecc':  'Eccentricity/raw',\n",
    "           'dist': 'SSSP/raw'}\n",
    "\n",
    "    torch.save(data_list, os.path.join('DATA', maps[task], f'{task}_25-35_data_list.pt'))\n",
    "    print(f'Task {task} preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess LRGB Datasets for PyDGN usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import LRGBDataset\n",
    "\n",
    "peptides_func_tr = LRGBDataset('DATA', 'Peptides-func', split='train')\n",
    "peptides_func_vl = LRGBDataset('DATA', 'Peptides-func', split='val')\n",
    "peptides_func_te = LRGBDataset('DATA', 'Peptides-func', split='test')\n",
    "\n",
    "peptides_struct_tr = LRGBDataset('DATA', 'Peptides-struct', split='train')\n",
    "peptides_struct_vl = LRGBDataset('DATA', 'Peptides-struct', split='val')\n",
    "peptides_struct_te = LRGBDataset('DATA', 'Peptides-struct', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_func = [d for d in peptides_func_tr] + [d for d in peptides_func_vl] + [d for d in peptides_func_te]\n",
    "peptides_struct = [d for d in peptides_struct_tr] + [d for d in peptides_struct_vl] + [d for d in peptides_struct_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15535, 15535)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peptides_func), len(peptides_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10873, 2331, 2331)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peptides_func_tr), len(peptides_func_vl), len(peptides_func_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10873, 2331, 2331)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peptides_struct_tr), len(peptides_struct_vl), len(peptides_struct_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import AddLaplacianEigenvectorPE, AddRandomWalkPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RWSE for peptides-func...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferrica/.venv/test-amp/lib/python3.10/site-packages/torch_sparse/matmul.py:97: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  C = torch.sparse.mm(A, B)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "Processing RWSE for peptides-struct...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "rwse = AddRandomWalkPE(walk_length=20)\n",
    "\n",
    "print('Processing RWSE for peptides-func...')\n",
    "i = 0\n",
    "for d in peptides_func:\n",
    "    rwse(d)\n",
    "\n",
    "    i+=1 \n",
    "    if i % 1000 == 0: \n",
    "        print(i)\n",
    "        \n",
    "print('Processing RWSE for peptides-struct...')\n",
    "i = 0\n",
    "for d in peptides_struct:\n",
    "    rwse(d)\n",
    "\n",
    "    i+=1 \n",
    "    if i % 1000 == 0: \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LapPE for peptides-func...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "Processing LapPE for peptides-struct `...\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import (\n",
    "    get_laplacian,\n",
    "    to_scipy_sparse_matrix,\n",
    ")\n",
    "\n",
    "def add_node_attr(data, value, attr_name = None):\n",
    "    # TODO Move to `BaseTransform`.\n",
    "    if attr_name is None:\n",
    "        if 'x' in data:\n",
    "            x = data.x.view(-1, 1) if data.x.dim() == 1 else data.x\n",
    "            data.x = torch.cat([x, value.to(x.device, x.dtype)], dim=-1)\n",
    "        else:\n",
    "            data.x = value\n",
    "    else:\n",
    "        data[attr_name] = value\n",
    "\n",
    "    return data\n",
    "\n",
    "# reproducing how LapPE are computed on GPS paper\n",
    "class LapPE_GPS:\n",
    "    # Number of nodes from which to use sparse eigenvector computation:\n",
    "    SPARSE_THRESHOLD: int = 100\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        k: int,\n",
    "        is_undirected: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.k = k  # max_frequencies\n",
    "        self.is_undirected = is_undirected\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def forward(self, data):\n",
    "        eps=1e-12\n",
    "        num_nodes = data.num_nodes\n",
    "\n",
    "        # GET LAPLACIAN\n",
    "        edge_index, edge_weight = get_laplacian(\n",
    "            data.edge_index,\n",
    "            data.edge_weight,\n",
    "            num_nodes=num_nodes,\n",
    "        )\n",
    "        L = to_scipy_sparse_matrix(edge_index, edge_weight, num_nodes)\n",
    "\n",
    "        evals, evects = np.linalg.eigh(L.toarray())\n",
    "\n",
    "        N = len(evals)  # Number of nodes, including disconnected nodes.\n",
    "        assert N == num_nodes\n",
    "        max_freqs = self.k\n",
    "    \n",
    "        # Keep up to the maximum desired number of frequencies.\n",
    "        idx = evals.argsort()[:max_freqs]\n",
    "        evals, evects = evals[idx], np.real(evects[:, idx])\n",
    "        evals = torch.from_numpy(np.real(evals)).clamp_min(0)\n",
    "        evects = torch.from_numpy(evects).float()\n",
    "\n",
    "        # L2 NORMALIZATION\n",
    "        denom = evects.norm(p=2, dim=0, keepdim=True)\n",
    "        denom = denom.clamp_min(eps).expand_as(evects)\n",
    "        evects = evects / denom\n",
    "\n",
    "        # PADDING EIGENVECTORS\n",
    "        if N < max_freqs:\n",
    "            EigVecs = F.pad(evects, (0, max_freqs - N), value=float('nan'))\n",
    "        else:\n",
    "            EigVecs = evects\n",
    "    \n",
    "        # PADDING EIGENVALUES\n",
    "        if N < max_freqs:\n",
    "            EigVals = F.pad(evals, (0, max_freqs - N), value=float('nan')).unsqueeze(0)\n",
    "        else:\n",
    "            EigVals = evals.unsqueeze(0)\n",
    "        EigVals = EigVals.repeat(N, 1).unsqueeze(2)\n",
    "\n",
    "        data = add_node_attr(data, EigVecs, attr_name='laplacian_eigenvector_pe')\n",
    "        data = add_node_attr(data, EigVals, attr_name='laplacian_eigenvalues_pe')\n",
    "        return data\n",
    "\n",
    "# errors = 0\n",
    "print('Processing LapPE for peptides-func...')\n",
    "i = 0\n",
    "for d in peptides_func:\n",
    "    lappe = LapPE_GPS(k=10)\n",
    "    lappe.forward(d)\n",
    "    \n",
    "    i+=1 \n",
    "    if i % 1000 == 0: \n",
    "        print(i)\n",
    "\n",
    "print('Processing LapPE for peptides-struct `...')\n",
    "i = 0\n",
    "for d in peptides_struct:\n",
    "    lappe = LapPE_GPS(k=10)\n",
    "    lappe.forward(d)\n",
    "    \n",
    "    i+=1 \n",
    "    if i % 1000 == 0: \n",
    "        print(i)                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save processed data\n",
    "torch.save(peptides_func, 'DATA/peptides-func/processed/data.pt')\n",
    "torch.save(peptides_struct, 'DATA/peptides-struct/processed/data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
